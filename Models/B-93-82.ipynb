{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70b3b2ab-eef3-4d1c-84e1-8149dd2f927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd74f6ca-9f50-4cf8-b283-018807caccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # transforms.Resize((224,224)),\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b387caad-b689-4e05-a1c9-e03f7a6681bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(trainset.targets),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00a164a4-0eaa-4ddb-95c7-240ddc202365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(testset.targets),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85a822cd-d419-491d-8e67-9ed0ed7fc4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91a7dcdc-d157-4c86-9e7f-9ca9500c507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=3, padding=1, bias=False)\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        out = self.conv2(self.relu(self.bn2(out)))\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "# ResNet architecture\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 32\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)  # For grayscale images\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def Resnet():\n",
    "    return ResNet(BasicBlock, [3, 6, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9cc5378-c455-4518-8d56-993cc24054cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=15, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f27b365f-2693-4c52-938d-24e9729b1d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883178"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a226c-9f34-4901-9ca9-9a112194dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad13c969-2b01-4d32-8eb0-eeff88023fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.410014\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.468668\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.212180\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.359720\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5462/10000 (55%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.038758\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.123184\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.862034\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.703086\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7035/10000 (70%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.676484\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.681581\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.647969\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.857744\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7439/10000 (74%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.555330\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.563555\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.401050\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.357865\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7616/10000 (76%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.514269\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.488718\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.525704\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.504725\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8182/10000 (82%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.317142\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.412032\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.463362\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.499554\n",
      "\n",
      "Test set: Average loss: 0.0059, Accuracy: 7980/10000 (80%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.548803\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.342032\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.298537\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.274739\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8251/10000 (83%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.314711\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.475152\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.282793\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.283880\n",
      "\n",
      "Test set: Average loss: 0.0056, Accuracy: 8209/10000 (82%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.298786\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.215860\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.248716\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.298882\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 8417/10000 (84%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.210325\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.239949\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.342109\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.275043\n",
      "\n",
      "Test set: Average loss: 0.0046, Accuracy: 8483/10000 (85%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.154880\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.243919\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.166105\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.203537\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8477/10000 (85%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.165526\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.236894\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.181591\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.112073\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 8594/10000 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.085744\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.223711\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.230801\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.238679\n",
      "\n",
      "Test set: Average loss: 0.0049, Accuracy: 8486/10000 (85%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.180039\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.176109\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.071465\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.196810\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8567/10000 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.113335\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.093471\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.170854\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.153709\n",
      "\n",
      "Test set: Average loss: 0.0051, Accuracy: 8445/10000 (84%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.110518\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.038912\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.104027\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.059587\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 8888/10000 (89%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.066241\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.049533\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.059939\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.067627\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 8933/10000 (89%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.025328\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.022683\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.009827\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.031677\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 8933/10000 (89%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.021342\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.031469\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.050013\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.008004\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.015251\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.027500\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.040274\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.033118\n",
      "\n",
      "Test set: Average loss: 0.0042, Accuracy: 8938/10000 (89%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.014488\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.028124\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.011661\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.014460\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.014824\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.003964\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.015008\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.027448\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 8948/10000 (89%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.007366\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.002483\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.003435\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.003243\n",
      "\n",
      "Test set: Average loss: 0.0046, Accuracy: 8937/10000 (89%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.011052\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.009442\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.003247\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.008537\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8942/10000 (89%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.003851\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.002413\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.004826\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.002186\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8933/10000 (89%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.007618\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.001734\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.001413\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.002637\n",
      "\n",
      "Test set: Average loss: 0.0049, Accuracy: 8942/10000 (89%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.003913\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.001738\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.001025\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.006327\n",
      "\n",
      "Test set: Average loss: 0.0050, Accuracy: 8941/10000 (89%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.003164\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.003894\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.003140\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.002924\n",
      "\n",
      "Test set: Average loss: 0.0051, Accuracy: 8932/10000 (89%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.008853\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.003313\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.002353\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.013091\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8923/10000 (89%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.001717\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.001549\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.001838\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.001299\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8938/10000 (89%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.001619\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.005806\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.015905\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.001141\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.003102\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.000587\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.001539\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.001864\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.001552\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.002471\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.001030\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.001480\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.001637\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.004286\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.004030\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.001187\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.000963\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.006640\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.002070\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.002123\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8923/10000 (89%)\n",
      "\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.001351\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.000758\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.001285\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.000789\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.001406\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.001109\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.000681\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.001549\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.000843\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.000810\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.001734\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.003238\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8929/10000 (89%)\n",
      "\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.002962\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.001678\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.001443\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.000734\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.001007\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.001698\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.002075\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.001858\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8916/10000 (89%)\n",
      "\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.001721\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.004539\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.002072\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.005643\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.002029\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.002423\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.002117\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.007113\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.004060\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.001649\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.001638\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.002278\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8921/10000 (89%)\n",
      "\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.001311\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.001309\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.002136\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.005989\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.001029\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.000933\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.001880\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.000934\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.001117\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.001442\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.001379\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.003188\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.001010\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.002776\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.001098\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.001848\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8919/10000 (89%)\n",
      "\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.003058\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.001849\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.001841\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.001257\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8930/10000 (89%)\n",
      "\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.000744\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.000943\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.000434\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.002316\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8926/10000 (89%)\n",
      "\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.001527\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.000834\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.002046\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.001087\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 8923/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training hyperparameters\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, trainloader, criterion, optimizer, epoch)\n",
    "    test(model, device, testloader, criterion)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ee9ed-7845-4d9f-b031-a52e9fd4cc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f82b7d-df56-4990-8e49-2653a5575d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model-Resnet30.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a93337-866e-4d97-b04d-871ee0800829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict1 = pickle.load(fo, encoding='bytes')\n",
    "    return dict1\n",
    "def model_test(model, data_path):\n",
    "    dict = unpickle(data_path)\n",
    "    data_test = dict[b'data']\n",
    "    model.eval()\n",
    "    pred = []\n",
    "\n",
    "    for i in range(data_test.shape[0]):\n",
    "        # Reshape from (3072,) to (3, 32, 32) for an RGB image\n",
    "        img_rgb = data_test[i].reshape(3, 32, 32).transpose((1, 2, 0))\n",
    "\n",
    "        # Convert to PIL image\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        # Apply the transformation\n",
    "        img_tensor = transform_test(img_pil)\n",
    "\n",
    "        # Add a batch dimension and send the image to the model\n",
    "        img_tensor = img_tensor.unsqueeze(0).cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f22db4f6-c2af-4edd-9fcd-4d89f606a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([ 932,  911,  917, 1199,  954, 1058,  926, 1004, 1027, 1072]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_test(model, \"cifar_test_nolabels.pkl\")\n",
    "np.unique(pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de68132d-e6d3-43bc-aad0-16b82da3000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict1 = pickle.load(fo, encoding='bytes')\n",
    "    return dict1\n",
    "\n",
    "dict = unpickle(\"cifar_test_nolabels.pkl\")\n",
    "df = pd.DataFrame({\"ID\" : dict[b'ids'], \"Labels\" : pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89b6a790-b10e-496e-bd5c-13bfbfe18deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Resnet-18-v2-batch256-sub9.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0938482c-279b-43fb-85a3-013fa6a45e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission9.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa530aa5-6591-445f-8040-fb7677b253d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       "3    1131\n",
       "5    1067\n",
       "8    1059\n",
       "9    1056\n",
       "7    1028\n",
       "1     961\n",
       "4     939\n",
       "6     932\n",
       "0     925\n",
       "2     902\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission10.csv\")['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ba780-3f1d-4f8c-acd4-364f0b1ec46b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
